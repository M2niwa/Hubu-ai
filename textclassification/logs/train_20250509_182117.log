2025-05-09 18:21:17,341 - INFO - ***** LSTM 训练开始 *****
2025-05-09 18:21:17,341 - INFO - 使用设备: cuda
2025-05-09 18:21:29,548 - INFO - 词汇表大小: 30000
2025-05-09 18:21:29,549 - INFO - 验证集样本数: 10000
2025-05-09 18:21:29,756 - INFO - 模型初始化完成
2025-05-09 18:21:31,574 - INFO - Epoch 1 | Step 0/6670 | Loss: 2.7164
2025-05-09 18:21:32,751 - INFO - Epoch 1 | Step 100/6670 | Loss: 2.7154
2025-05-09 18:21:33,929 - INFO - Epoch 1 | Step 200/6670 | Loss: 2.7131
2025-05-09 18:21:35,088 - INFO - Epoch 1 | Step 300/6670 | Loss: 2.7114
2025-05-09 18:21:36,233 - INFO - Epoch 1 | Step 400/6670 | Loss: 2.7114
2025-05-09 18:21:37,408 - INFO - Epoch 1 | Step 500/6670 | Loss: 2.7100
2025-05-09 18:21:38,626 - INFO - Epoch 1 | Step 600/6670 | Loss: 2.7090
2025-05-09 18:21:39,813 - INFO - Epoch 1 | Step 700/6670 | Loss: 2.7077
2025-05-09 18:21:40,974 - INFO - Epoch 1 | Step 800/6670 | Loss: 2.7063
2025-05-09 18:21:42,144 - INFO - Epoch 1 | Step 900/6670 | Loss: 2.7055
2025-05-09 18:21:43,317 - INFO - Epoch 1 | Step 1000/6670 | Loss: 2.7054
2025-05-09 18:21:44,484 - INFO - Epoch 1 | Step 1100/6670 | Loss: 2.7049
2025-05-09 18:21:45,707 - INFO - Epoch 1 | Step 1200/6670 | Loss: 2.7039
2025-05-09 18:21:46,944 - INFO - Epoch 1 | Step 1300/6670 | Loss: 2.7027
2025-05-09 18:21:48,300 - INFO - Epoch 1 | Step 1400/6670 | Loss: 2.7013
2025-05-09 18:21:49,494 - INFO - Epoch 1 | Step 1500/6670 | Loss: 2.7001
2025-05-09 18:21:50,648 - INFO - Epoch 1 | Step 1600/6670 | Loss: 2.6989
2025-05-09 18:21:51,802 - INFO - Epoch 1 | Step 1700/6670 | Loss: 2.6977
2025-05-09 18:21:53,017 - INFO - Epoch 1 | Step 1800/6670 | Loss: 2.6969
2025-05-09 18:21:54,167 - INFO - Epoch 1 | Step 1900/6670 | Loss: 2.6958
2025-05-09 18:21:55,348 - INFO - Epoch 1 | Step 2000/6670 | Loss: 2.6949
2025-05-09 18:21:56,529 - INFO - Epoch 1 | Step 2100/6670 | Loss: 2.6940
2025-05-09 18:21:57,702 - INFO - Epoch 1 | Step 2200/6670 | Loss: 2.6931
2025-05-09 18:21:58,881 - INFO - Epoch 1 | Step 2300/6670 | Loss: 2.6922
2025-05-09 18:22:00,058 - INFO - Epoch 1 | Step 2400/6670 | Loss: 2.6914
2025-05-09 18:22:01,248 - INFO - Epoch 1 | Step 2500/6670 | Loss: 2.6902
2025-05-09 18:22:02,529 - INFO - Epoch 1 | Step 2600/6670 | Loss: 2.6895
2025-05-09 18:22:03,725 - INFO - Epoch 1 | Step 2700/6670 | Loss: 2.6888
2025-05-09 18:22:04,896 - INFO - Epoch 1 | Step 2800/6670 | Loss: 2.6878
2025-05-09 18:22:06,071 - INFO - Epoch 1 | Step 2900/6670 | Loss: 2.6868
2025-05-09 18:22:07,244 - INFO - Epoch 1 | Step 3000/6670 | Loss: 2.6860
2025-05-09 18:22:08,464 - INFO - Epoch 1 | Step 3100/6670 | Loss: 2.6850
2025-05-09 18:22:09,642 - INFO - Epoch 1 | Step 3200/6670 | Loss: 2.6844
2025-05-09 18:22:10,814 - INFO - Epoch 1 | Step 3300/6670 | Loss: 2.6836
2025-05-09 18:22:12,010 - INFO - Epoch 1 | Step 3400/6670 | Loss: 2.6829
2025-05-09 18:22:13,187 - INFO - Epoch 1 | Step 3500/6670 | Loss: 2.6820
2025-05-09 18:22:14,387 - INFO - Epoch 1 | Step 3600/6670 | Loss: 2.6813
2025-05-09 18:22:15,569 - INFO - Epoch 1 | Step 3700/6670 | Loss: 2.6804
2025-05-09 18:22:16,769 - INFO - Epoch 1 | Step 3800/6670 | Loss: 2.6793
2025-05-09 18:22:17,964 - INFO - Epoch 1 | Step 3900/6670 | Loss: 2.6785
2025-05-09 18:22:19,139 - INFO - Epoch 1 | Step 4000/6670 | Loss: 2.6777
2025-05-09 18:22:20,304 - INFO - Epoch 1 | Step 4100/6670 | Loss: 2.6768
2025-05-09 18:22:21,491 - INFO - Epoch 1 | Step 4200/6670 | Loss: 2.6759
2025-05-09 18:22:22,652 - INFO - Epoch 1 | Step 4300/6670 | Loss: 2.6750
2025-05-09 18:22:23,853 - INFO - Epoch 1 | Step 4400/6670 | Loss: 2.6743
2025-05-09 18:22:25,042 - INFO - Epoch 1 | Step 4500/6670 | Loss: 2.6733
2025-05-09 18:22:26,228 - INFO - Epoch 1 | Step 4600/6670 | Loss: 2.6726
2025-05-09 18:22:27,398 - INFO - Epoch 1 | Step 4700/6670 | Loss: 2.6717
2025-05-09 18:22:28,599 - INFO - Epoch 1 | Step 4800/6670 | Loss: 2.6708
2025-05-09 18:22:29,774 - INFO - Epoch 1 | Step 4900/6670 | Loss: 2.6699
2025-05-09 18:22:30,960 - INFO - Epoch 1 | Step 5000/6670 | Loss: 2.6690
2025-05-09 18:22:32,156 - INFO - Epoch 1 | Step 5100/6670 | Loss: 2.6681
2025-05-09 18:22:33,345 - INFO - Epoch 1 | Step 5200/6670 | Loss: 2.6672
2025-05-09 18:22:34,559 - INFO - Epoch 1 | Step 5300/6670 | Loss: 2.6663
2025-05-09 18:22:35,734 - INFO - Epoch 1 | Step 5400/6670 | Loss: 2.6653
2025-05-09 18:22:36,921 - INFO - Epoch 1 | Step 5500/6670 | Loss: 2.6643
2025-05-09 18:22:38,106 - INFO - Epoch 1 | Step 5600/6670 | Loss: 2.6632
2025-05-09 18:22:39,279 - INFO - Epoch 1 | Step 5700/6670 | Loss: 2.6624
2025-05-09 18:22:40,474 - INFO - Epoch 1 | Step 5800/6670 | Loss: 2.6617
2025-05-09 18:22:41,659 - INFO - Epoch 1 | Step 5900/6670 | Loss: 2.6608
2025-05-09 18:22:42,834 - INFO - Epoch 1 | Step 6000/6670 | Loss: 2.6598
2025-05-09 18:22:44,045 - INFO - Epoch 1 | Step 6100/6670 | Loss: 2.6589
2025-05-09 18:22:45,209 - INFO - Epoch 1 | Step 6200/6670 | Loss: 2.6580
2025-05-09 18:22:46,396 - INFO - Epoch 1 | Step 6300/6670 | Loss: 2.6572
2025-05-09 18:22:47,575 - INFO - Epoch 1 | Step 6400/6670 | Loss: 2.6563
2025-05-09 18:22:48,758 - INFO - Epoch 1 | Step 6500/6670 | Loss: 2.6555
2025-05-09 18:22:49,940 - INFO - Epoch 1 | Step 6600/6670 | Loss: 2.6545
2025-05-09 18:22:55,646 - INFO - Epoch 1 结果 || 训练损失: 2.6538 | 验证损失: 2.5927 | 准确率: 0.1501 | F1分数: 0.1161
2025-05-09 18:22:55,672 - INFO - 保存最佳模型到: ./checkpoints/best_lstm_model_epoch1.pth
2025-05-09 18:22:55,710 - INFO - Epoch 2 | Step 0/6670 | Loss: 2.7014
2025-05-09 18:22:57,021 - INFO - Epoch 2 | Step 100/6670 | Loss: 2.5926
2025-05-09 18:22:58,170 - INFO - Epoch 2 | Step 200/6670 | Loss: 2.5879
2025-05-09 18:22:59,323 - INFO - Epoch 2 | Step 300/6670 | Loss: 2.5847
2025-05-09 18:23:00,487 - INFO - Epoch 2 | Step 400/6670 | Loss: 2.5841
2025-05-09 18:23:01,658 - INFO - Epoch 2 | Step 500/6670 | Loss: 2.5820
2025-05-09 18:23:02,900 - INFO - Epoch 2 | Step 600/6670 | Loss: 2.5798
2025-05-09 18:23:04,089 - INFO - Epoch 2 | Step 700/6670 | Loss: 2.5782
2025-05-09 18:23:05,264 - INFO - Epoch 2 | Step 800/6670 | Loss: 2.5797
2025-05-09 18:23:06,427 - INFO - Epoch 2 | Step 900/6670 | Loss: 2.5789
2025-05-09 18:23:07,613 - INFO - Epoch 2 | Step 1000/6670 | Loss: 2.5798
2025-05-09 18:23:08,767 - INFO - Epoch 2 | Step 1100/6670 | Loss: 2.5800
2025-05-09 18:23:09,949 - INFO - Epoch 2 | Step 1200/6670 | Loss: 2.5806
2025-05-09 18:23:11,106 - INFO - Epoch 2 | Step 1300/6670 | Loss: 2.5798
2025-05-09 18:23:12,302 - INFO - Epoch 2 | Step 1400/6670 | Loss: 2.5791
2025-05-09 18:23:13,484 - INFO - Epoch 2 | Step 1500/6670 | Loss: 2.5790
2025-05-09 18:23:14,681 - INFO - Epoch 2 | Step 1600/6670 | Loss: 2.5783
2025-05-09 18:23:15,948 - INFO - Epoch 2 | Step 1700/6670 | Loss: 2.5779
2025-05-09 18:23:17,213 - INFO - Epoch 2 | Step 1800/6670 | Loss: 2.5774
2025-05-09 18:23:18,374 - INFO - Epoch 2 | Step 1900/6670 | Loss: 2.5764
2025-05-09 18:23:19,578 - INFO - Epoch 2 | Step 2000/6670 | Loss: 2.5768
2025-05-09 18:23:20,783 - INFO - Epoch 2 | Step 2100/6670 | Loss: 2.5761
2025-05-09 18:23:22,016 - INFO - Epoch 2 | Step 2200/6670 | Loss: 2.5742
2025-05-09 18:23:23,216 - INFO - Epoch 2 | Step 2300/6670 | Loss: 2.5744
2025-05-09 18:23:24,389 - INFO - Epoch 2 | Step 2400/6670 | Loss: 2.5740
2025-05-09 18:23:25,583 - INFO - Epoch 2 | Step 2500/6670 | Loss: 2.5732
2025-05-09 18:23:26,787 - INFO - Epoch 2 | Step 2600/6670 | Loss: 2.5719
2025-05-09 18:23:28,033 - INFO - Epoch 2 | Step 2700/6670 | Loss: 2.5712
2025-05-09 18:23:29,391 - INFO - Epoch 2 | Step 2800/6670 | Loss: 2.5700
2025-05-09 18:23:30,807 - INFO - Epoch 2 | Step 2900/6670 | Loss: 2.5692
2025-05-09 18:23:32,288 - INFO - Epoch 2 | Step 3000/6670 | Loss: 2.5681
2025-05-09 18:23:33,550 - INFO - Epoch 2 | Step 3100/6670 | Loss: 2.5680
2025-05-09 18:23:34,820 - INFO - Epoch 2 | Step 3200/6670 | Loss: 2.5671
2025-05-09 18:23:36,335 - INFO - Epoch 2 | Step 3300/6670 | Loss: 2.5671
2025-05-09 18:23:37,875 - INFO - Epoch 2 | Step 3400/6670 | Loss: 2.5662
2025-05-09 18:23:39,413 - INFO - Epoch 2 | Step 3500/6670 | Loss: 2.5658
2025-05-09 18:23:40,711 - INFO - Epoch 2 | Step 3600/6670 | Loss: 2.5651
2025-05-09 18:23:42,326 - INFO - Epoch 2 | Step 3700/6670 | Loss: 2.5645
2025-05-09 18:23:43,568 - INFO - Epoch 2 | Step 3800/6670 | Loss: 2.5642
2025-05-09 18:23:44,773 - INFO - Epoch 2 | Step 3900/6670 | Loss: 2.5639
2025-05-09 18:23:45,992 - INFO - Epoch 2 | Step 4000/6670 | Loss: 2.5629
2025-05-09 18:23:47,178 - INFO - Epoch 2 | Step 4100/6670 | Loss: 2.5625
2025-05-09 18:23:48,400 - INFO - Epoch 2 | Step 4200/6670 | Loss: 2.5618
2025-05-09 18:23:49,633 - INFO - Epoch 2 | Step 4300/6670 | Loss: 2.5616
2025-05-09 18:23:50,819 - INFO - Epoch 2 | Step 4400/6670 | Loss: 2.5609
2025-05-09 18:23:52,016 - INFO - Epoch 2 | Step 4500/6670 | Loss: 2.5597
2025-05-09 18:23:53,236 - INFO - Epoch 2 | Step 4600/6670 | Loss: 2.5590
2025-05-09 18:23:54,446 - INFO - Epoch 2 | Step 4700/6670 | Loss: 2.5581
2025-05-09 18:23:55,672 - INFO - Epoch 2 | Step 4800/6670 | Loss: 2.5578
2025-05-09 18:23:56,912 - INFO - Epoch 2 | Step 4900/6670 | Loss: 2.5570
2025-05-09 18:23:58,119 - INFO - Epoch 2 | Step 5000/6670 | Loss: 2.5569
2025-05-09 18:23:59,421 - INFO - Epoch 2 | Step 5100/6670 | Loss: 2.5567
2025-05-09 18:24:00,704 - INFO - Epoch 2 | Step 5200/6670 | Loss: 2.5565
2025-05-09 18:24:01,915 - INFO - Epoch 2 | Step 5300/6670 | Loss: 2.5556
2025-05-09 18:24:03,212 - INFO - Epoch 2 | Step 5400/6670 | Loss: 2.5552
2025-05-09 18:24:04,481 - INFO - Epoch 2 | Step 5500/6670 | Loss: 2.5549
2025-05-09 18:24:05,708 - INFO - Epoch 2 | Step 5600/6670 | Loss: 2.5545
2025-05-09 18:24:06,893 - INFO - Epoch 2 | Step 5700/6670 | Loss: 2.5543
2025-05-09 18:24:08,095 - INFO - Epoch 2 | Step 5800/6670 | Loss: 2.5534
2025-05-09 18:24:09,309 - INFO - Epoch 2 | Step 5900/6670 | Loss: 2.5528
2025-05-09 18:24:10,497 - INFO - Epoch 2 | Step 6000/6670 | Loss: 2.5526
2025-05-09 18:24:11,681 - INFO - Epoch 2 | Step 6100/6670 | Loss: 2.5521
2025-05-09 18:24:12,852 - INFO - Epoch 2 | Step 6200/6670 | Loss: 2.5519
2025-05-09 18:24:14,046 - INFO - Epoch 2 | Step 6300/6670 | Loss: 2.5510
2025-05-09 18:24:15,209 - INFO - Epoch 2 | Step 6400/6670 | Loss: 2.5504
2025-05-09 18:24:16,410 - INFO - Epoch 2 | Step 6500/6670 | Loss: 2.5497
2025-05-09 18:24:17,605 - INFO - Epoch 2 | Step 6600/6670 | Loss: 2.5491
2025-05-09 18:24:23,152 - INFO - Epoch 2 结果 || 训练损失: 2.5484 | 验证损失: 2.5193 | 准确率: 0.1753 | F1分数: 0.1287
2025-05-09 18:24:23,181 - INFO - 保存最佳模型到: ./checkpoints/best_lstm_model_epoch2.pth
2025-05-09 18:24:23,210 - INFO - Epoch 3 | Step 0/6670 | Loss: 2.3145
2025-05-09 18:24:24,708 - INFO - Epoch 3 | Step 100/6670 | Loss: 2.5315
2025-05-09 18:24:26,018 - INFO - Epoch 3 | Step 200/6670 | Loss: 2.5059
2025-05-09 18:24:27,382 - INFO - Epoch 3 | Step 300/6670 | Loss: 2.5105
2025-05-09 18:24:28,873 - INFO - Epoch 3 | Step 400/6670 | Loss: 2.5137
2025-05-09 18:24:30,328 - INFO - Epoch 3 | Step 500/6670 | Loss: 2.5129
2025-05-09 18:24:31,815 - INFO - Epoch 3 | Step 600/6670 | Loss: 2.5121
2025-05-09 18:24:33,113 - INFO - Epoch 3 | Step 700/6670 | Loss: 2.5129
2025-05-09 18:24:34,380 - INFO - Epoch 3 | Step 800/6670 | Loss: 2.5098
2025-05-09 18:24:35,658 - INFO - Epoch 3 | Step 900/6670 | Loss: 2.5137
2025-05-09 18:24:36,850 - INFO - Epoch 3 | Step 1000/6670 | Loss: 2.5135
2025-05-09 18:24:38,103 - INFO - Epoch 3 | Step 1100/6670 | Loss: 2.5110
2025-05-09 18:24:39,482 - INFO - Epoch 3 | Step 1200/6670 | Loss: 2.5102
2025-05-09 18:24:40,760 - INFO - Epoch 3 | Step 1300/6670 | Loss: 2.5109
2025-05-09 18:24:42,036 - INFO - Epoch 3 | Step 1400/6670 | Loss: 2.5098
2025-05-09 18:24:43,278 - INFO - Epoch 3 | Step 1500/6670 | Loss: 2.5094
2025-05-09 18:24:44,486 - INFO - Epoch 3 | Step 1600/6670 | Loss: 2.5094
2025-05-09 18:24:45,693 - INFO - Epoch 3 | Step 1700/6670 | Loss: 2.5089
2025-05-09 18:24:46,955 - INFO - Epoch 3 | Step 1800/6670 | Loss: 2.5076
2025-05-09 18:24:48,251 - INFO - Epoch 3 | Step 1900/6670 | Loss: 2.5064
2025-05-09 18:24:49,513 - INFO - Epoch 3 | Step 2000/6670 | Loss: 2.5051
2025-05-09 18:24:50,785 - INFO - Epoch 3 | Step 2100/6670 | Loss: 2.5029
2025-05-09 18:24:52,072 - INFO - Epoch 3 | Step 2200/6670 | Loss: 2.5013
2025-05-09 18:24:53,321 - INFO - Epoch 3 | Step 2300/6670 | Loss: 2.4995
2025-05-09 18:24:54,609 - INFO - Epoch 3 | Step 2400/6670 | Loss: 2.4994
2025-05-09 18:24:55,916 - INFO - Epoch 3 | Step 2500/6670 | Loss: 2.5004
2025-05-09 18:24:57,215 - INFO - Epoch 3 | Step 2600/6670 | Loss: 2.5007
2025-05-09 18:24:58,466 - INFO - Epoch 3 | Step 2700/6670 | Loss: 2.5019
2025-05-09 18:24:59,697 - INFO - Epoch 3 | Step 2800/6670 | Loss: 2.5016
2025-05-09 18:25:00,927 - INFO - Epoch 3 | Step 2900/6670 | Loss: 2.5020
2025-05-09 18:25:02,241 - INFO - Epoch 3 | Step 3000/6670 | Loss: 2.5020
2025-05-09 18:25:03,455 - INFO - Epoch 3 | Step 3100/6670 | Loss: 2.5013
2025-05-09 18:25:04,648 - INFO - Epoch 3 | Step 3200/6670 | Loss: 2.5001
2025-05-09 18:25:05,942 - INFO - Epoch 3 | Step 3300/6670 | Loss: 2.4998
2025-05-09 18:25:07,216 - INFO - Epoch 3 | Step 3400/6670 | Loss: 2.5002
2025-05-09 18:25:08,424 - INFO - Epoch 3 | Step 3500/6670 | Loss: 2.5006
2025-05-09 18:25:09,611 - INFO - Epoch 3 | Step 3600/6670 | Loss: 2.5004
2025-05-09 18:25:10,848 - INFO - Epoch 3 | Step 3700/6670 | Loss: 2.5002
2025-05-09 18:25:12,102 - INFO - Epoch 3 | Step 3800/6670 | Loss: 2.4987
2025-05-09 18:25:13,302 - INFO - Epoch 3 | Step 3900/6670 | Loss: 2.4990
2025-05-09 18:25:14,526 - INFO - Epoch 3 | Step 4000/6670 | Loss: 2.4991
2025-05-09 18:25:15,745 - INFO - Epoch 3 | Step 4100/6670 | Loss: 2.4983
2025-05-09 18:25:17,010 - INFO - Epoch 3 | Step 4200/6670 | Loss: 2.4975
2025-05-09 18:25:18,266 - INFO - Epoch 3 | Step 4300/6670 | Loss: 2.4976
2025-05-09 18:25:19,488 - INFO - Epoch 3 | Step 4400/6670 | Loss: 2.4971
2025-05-09 18:25:20,725 - INFO - Epoch 3 | Step 4500/6670 | Loss: 2.4970
2025-05-09 18:25:21,908 - INFO - Epoch 3 | Step 4600/6670 | Loss: 2.4967
2025-05-09 18:25:23,103 - INFO - Epoch 3 | Step 4700/6670 | Loss: 2.4967
2025-05-09 18:25:24,271 - INFO - Epoch 3 | Step 4800/6670 | Loss: 2.4960
2025-05-09 18:25:25,426 - INFO - Epoch 3 | Step 4900/6670 | Loss: 2.4956
2025-05-09 18:25:26,606 - INFO - Epoch 3 | Step 5000/6670 | Loss: 2.4954
2025-05-09 18:25:27,759 - INFO - Epoch 3 | Step 5100/6670 | Loss: 2.4949
2025-05-09 18:25:28,911 - INFO - Epoch 3 | Step 5200/6670 | Loss: 2.4943
2025-05-09 18:25:30,149 - INFO - Epoch 3 | Step 5300/6670 | Loss: 2.4934
2025-05-09 18:25:31,361 - INFO - Epoch 3 | Step 5400/6670 | Loss: 2.4929
2025-05-09 18:25:32,545 - INFO - Epoch 3 | Step 5500/6670 | Loss: 2.4927
2025-05-09 18:25:33,730 - INFO - Epoch 3 | Step 5600/6670 | Loss: 2.4929
2025-05-09 18:25:34,887 - INFO - Epoch 3 | Step 5700/6670 | Loss: 2.4929
2025-05-09 18:25:36,159 - INFO - Epoch 3 | Step 5800/6670 | Loss: 2.4923
2025-05-09 18:25:37,323 - INFO - Epoch 3 | Step 5900/6670 | Loss: 2.4921
2025-05-09 18:25:38,497 - INFO - Epoch 3 | Step 6000/6670 | Loss: 2.4918
2025-05-09 18:25:39,681 - INFO - Epoch 3 | Step 6100/6670 | Loss: 2.4914
2025-05-09 18:25:40,849 - INFO - Epoch 3 | Step 6200/6670 | Loss: 2.4908
2025-05-09 18:25:42,008 - INFO - Epoch 3 | Step 6300/6670 | Loss: 2.4903
2025-05-09 18:25:43,217 - INFO - Epoch 3 | Step 6400/6670 | Loss: 2.4899
2025-05-09 18:25:44,387 - INFO - Epoch 3 | Step 6500/6670 | Loss: 2.4893
2025-05-09 18:25:45,609 - INFO - Epoch 3 | Step 6600/6670 | Loss: 2.4893
2025-05-09 18:25:51,058 - INFO - Epoch 3 结果 || 训练损失: 2.4890 | 验证损失: 2.4668 | 准确率: 0.1998 | F1分数: 0.1524
2025-05-09 18:25:51,082 - INFO - 保存最佳模型到: ./checkpoints/best_lstm_model_epoch3.pth
